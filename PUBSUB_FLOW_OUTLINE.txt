===============================================================================
                        PUB/SUB FLOW OUTLINE - AUDIO ANALYSIS SYSTEM
===============================================================================

OVERVIEW
========
This system processes student audio submissions through a distributed pub/sub 
architecture using Google Cloud Pub/Sub with push-based webhooks. The flow 
handles audio conversion, transcription, and multiple analysis services 
(pronunciation, grammar, lexical, fluency) in parallel.

ARCHITECTURE TYPE
=================
- Push-based Google Cloud Pub/Sub (migrated from pull-based)
- Webhook-driven processing
- Parallel processing streams
- Centralized file management
- Coordinated cleanup system

===============================================================================
                                TOPICS & SUBSCRIPTIONS
===============================================================================

TOPICS CONFIGURATION
===================
1. student-submission-topic          - Entry point for new submissions
2. audio-conversion-done-topic       - Audio processing completion
3. transcription-done-topic          - Transcription completion  
4. question-analysis-ready-topic     - Both audio + transcription ready
5. pronoun-done-topic               - Pronunciation analysis complete
6. grammer-done-topic               - Grammar analysis complete
7. lexical-done-topic               - Lexical analysis complete
8. fluency-done-topic               - Fluency analysis complete
9. analysis-complete-topic          - All analysis services complete
10. submission-analyis-complete-topic - Final submission completion

SUBSCRIPTIONS CONFIGURATION
===========================
Topic: student-submission-topic
└── student-submission-topic-sub → /webhooks/student-submission

Topic: audio-conversion-done-topic  
└── audio-conversion-service-sub → /webhooks/audio-conversion-done

Topic: transcription-done-topic
└── transcription-service-sub → /webhooks/transcription-done

Topic: question-analysis-ready-topic
└── question-analysis-ready-topic-sub → /webhooks/question-analysis-ready

Topic: pronoun-done-topic
└── pronoun-done-topic-sub → /webhooks/pronunciation-done

Topic: grammer-done-topic
└── grammer-done-topic-sub → /webhooks/grammar-done

Topic: lexical-done-topic
└── lexical-done-topic-sub → /webhooks/lexical-done

Topic: fluency-done-topic
└── fluency-done-topic-sub → /webhooks/fluency-done

Topic: analysis-complete-topic
└── analysis-complete-topic-sub → /webhooks/analysis-complete

===============================================================================
                                COMPLETE MESSAGE FLOW
===============================================================================

STEP 1: SUBMISSION ENTRY
========================
Entry Point: POST /api/v1/submission/submit
Input: {
  "audio_urls": ["url1", "url2", "url3"],
  "submission_url": "unique_submission_id"
}

Action: Publishes to student-submission-topic
Message: {
  "audio_urls": ["url1", "url2", "url3"],
  "submission_url": "unique_submission_id",
  "total_questions": 3
}

STEP 2: PARALLEL PROCESSING INITIATION
======================================
Trigger: student-submission-topic → /webhooks/student-submission
Handler: SubmissionWebhook.handle_student_submission_webhook()

Action: Starts TWO parallel processing streams:
├── AudioWebhook.process_submission_for_audio()
└── TranscriptionWebhook.process_submission_for_transcription()

STEP 3A: AUDIO PROCESSING STREAM
================================
Service: AudioService
Process: For each audio URL:
  1. Download audio file
  2. Convert to WAV format
  3. Generate session_id for file lifecycle tracking
  4. Register file with FileManagerService
  5. Publish completion message

Publishes to: audio-conversion-done-topic
Message per question: {
  "wav_path": "/tmp/converted_audio.wav",
  "session_id": "session_123456_1_1703123456",
  "question_number": 1,
  "submission_url": "unique_submission_id",
  "original_audio_url": "url1",
  "total_questions": 3
}

STEP 3B: TRANSCRIPTION PROCESSING STREAM  
========================================
Service: TranscriptionService
Process: For each audio URL:
  1. Download audio file
  2. Send to transcription service (Whisper/external API)
  3. Extract transcript text
  4. Publish completion message

Publishes to: transcription-done-topic
Message per question: {
  "transcript": "transcribed text content",
  "question_number": 1,
  "submission_url": "unique_submission_id",
  "original_audio_url": "url1",
  "total_questions": 3
}

STEP 4: ANALYSIS COORDINATION
============================
Trigger: Both audio-conversion-done-topic AND transcription-done-topic
Handler: AnalysisCoordinatorService

Process:
1. Waits for BOTH audio and transcription completion for each question
2. When both are ready, combines the data
3. Publishes to question-analysis-ready-topic

Publishes to: question-analysis-ready-topic
Message per question: {
  "wav_path": "/tmp/converted_audio.wav",
  "session_id": "session_123456_1_1703123456",
  "transcript": "transcribed text content",
  "question_number": 1,
  "submission_url": "unique_submission_id",
  "original_audio_url": "url1",
  "total_questions": 3
}

STEP 5: PARALLEL ANALYSIS SERVICES
==================================
Trigger: question-analysis-ready-topic → /webhooks/question-analysis-ready
Handler: AnalysisWebhook.handle_question_analysis_ready_webhook()

Starts FOUR parallel analysis services:

5A. PRONUNCIATION ANALYSIS
--------------------------
Service: PronunciationService
Input: WAV file path + transcript + session_id
Process: 
  - Phoneme analysis
  - Pronunciation scoring
  - Word-level feedback
  - Marks service complete with FileManager
Publishes to: pronoun-done-topic

5B. GRAMMAR ANALYSIS
-------------------
Service: GrammarService  
Input: Transcript text
Process:
  - Grammar error detection
  - Sentence structure analysis
  - Correction suggestions
Publishes to: grammer-done-topic

5C. LEXICAL ANALYSIS
-------------------
Service: LexicalService
Input: Transcript text
Process:
  - Vocabulary assessment
  - Word complexity analysis
  - Lexical diversity scoring
Publishes to: lexical-done-topic

5D. FLUENCY ANALYSIS
-------------------
Service: FluencyService
Input: WAV file path + transcript
Process:
  - Speech rate analysis
  - Pause detection
  - Fluency scoring
Publishes to: fluency-done-topic

STEP 6: ANALYSIS COMPLETION COORDINATION
========================================
Trigger: All four analysis services complete (pronoun-done, grammer-done, lexical-done, fluency-done)
Handler: AnalysisWebhook (tracks completion of all services)

Process:
1. Waits for ALL four analysis services to complete for each question
2. Combines all analysis results
3. Publishes final completion message

Publishes to: analysis-complete-topic
Message: {
  "submission_url": "unique_submission_id",
  "question_number": 1,
  "pronunciation_results": {...},
  "grammar_results": {...},
  "lexical_results": {...},
  "fluency_results": {...},
  "combined_score": 85.5
}

STEP 7: FINAL SUBMISSION COMPLETION
===================================
Trigger: analysis-complete-topic for ALL questions in submission
Handler: Final completion webhook

Process:
1. Aggregates results from all questions
2. Calculates overall submission score
3. Updates database with final results
4. Triggers any final notifications

===============================================================================
                                FILE LIFECYCLE MANAGEMENT
===============================================================================

CENTRALIZED FILE PROCESSING
===========================
Problem Solved: Eliminated duplicate downloads and premature file cleanup

Components:
- FileManagerService: Tracks file sessions and coordinates cleanup
- Session IDs: Unique identifiers for file lifecycle tracking
- Dependency tracking: Knows which services need each file

Flow:
1. AudioService converts file → Registers with FileManager
2. Session ID passed through all messages
3. Services mark completion when done
4. FileManager cleans up when all services complete
5. Failsafe cleanup after 30 minutes

Benefits:
- 50% reduction in network calls (no duplicate downloads)
- 50% reduction in CPU usage (no duplicate conversions)
- Eliminated race conditions
- Proper resource cleanup

===============================================================================
                                WEBHOOK ENDPOINTS
===============================================================================

WEBHOOK MAPPING
===============
/webhooks/student-submission        ← student-submission-topic
/webhooks/audio-conversion-done     ← audio-conversion-done-topic
/webhooks/transcription-done        ← transcription-done-topic
/webhooks/question-analysis-ready   ← question-analysis-ready-topic
/webhooks/pronunciation-done        ← pronoun-done-topic
/webhooks/grammar-done              ← grammer-done-topic
/webhooks/lexical-done              ← lexical-done-topic
/webhooks/fluency-done              ← fluency-done-topic
/webhooks/analysis-complete         ← analysis-complete-topic

WEBHOOK HANDLERS
===============
SubmissionWebhook     - Coordinates parallel audio + transcription processing
AudioWebhook          - Handles audio conversion completion
TranscriptionWebhook  - Handles transcription completion
AnalysisWebhook       - Coordinates all analysis services and final completion

===============================================================================
                                SERVICES ARCHITECTURE
===============================================================================

CORE SERVICES
=============
1. SubmissionService      - Entry point handling
2. AudioService          - Audio download and conversion
3. TranscriptionService  - Speech-to-text processing
4. AnalysisCoordinatorService - Coordinates audio + transcription readiness
5. PronunciationService  - Phoneme and pronunciation analysis
6. GrammarService        - Grammar and syntax analysis
7. LexicalService        - Vocabulary and lexical analysis
8. FluencyService        - Speech fluency and coherence analysis
9. FileManagerService    - Centralized file lifecycle management
10. DatabaseService      - Data persistence and retrieval

SERVICE DEPENDENCIES
===================
SubmissionService → AudioService + TranscriptionService (parallel)
AudioService → FileManagerService (file registration)
AnalysisCoordinatorService → All Analysis Services (parallel)
PronunciationService → FileManagerService (completion marking)
All Services → DatabaseService (result storage)

===============================================================================
                                ERROR HANDLING & MONITORING
===============================================================================

ERROR HANDLING STRATEGY
=======================
- Services mark completion even on errors (prevents hanging)
- Return exceptions=True in asyncio.gather() for parallel processing
- Automatic failsafe cleanup prevents resource leaks
- Proper HTTP status codes for webhook responses

MONITORING CAPABILITIES
======================
Debug Endpoints:
- GET /api/v1/debug/file-sessions - View active file sessions
- POST /api/v1/debug/cleanup-session/{session_id} - Force cleanup
- POST /api/v1/debug/periodic-cleanup - Manual cleanup trigger

Logging:
- Detailed logging at each step
- Message ID tracking
- Session ID tracking throughout pipeline
- Error logging with context

TROUBLESHOOTING
==============
Common Issues:
1. Files not cleaned up → Check debug endpoints, verify service completion
2. Infinite loops → Fixed by eliminating duplicate subscriptions
3. Missing session IDs → Verify message format includes session_id
4. High disk usage → Monitor active sessions, adjust cleanup timeout

===============================================================================
                                DEPLOYMENT CONFIGURATION
===============================================================================

ENVIRONMENT VARIABLES
====================
BASE_WEBHOOK_URL=https://your-app-domain.com
GOOGLE_CLOUD_PROJECT=your-project-id
GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json
PUBSUB_WEBHOOK_AUTH_TOKEN=your-secret-token (optional)
LOCAL_BACKUP_DIR=output (for local fallback)

GOOGLE CLOUD SETUP
==================
1. Create all topics using gcloud commands
2. Create push subscriptions with webhook endpoints
3. Configure authentication tokens
4. Set up monitoring and alerting

SECURITY
========
- Webhook authentication via PUBSUB_WEBHOOK_AUTH_TOKEN
- Pub/Sub message validation
- Base64 encoded message data with automatic parsing
- CORS configuration for allowed origins

===============================================================================
                                PERFORMANCE CHARACTERISTICS
===============================================================================

SCALABILITY
===========
- Real-time processing (no polling delays)
- Automatic scaling based on message volume
- Parallel processing at multiple levels
- Resource-efficient (no continuous polling)

THROUGHPUT
==========
- Multiple submissions processed simultaneously
- Each submission processes multiple questions in parallel
- Analysis services run in parallel per question
- File processing optimized (single download/conversion per file)

RELIABILITY
===========
- Push-based webhooks for immediate processing
- Coordinated state management
- Automatic cleanup and resource management
- Error handling with graceful degradation

===============================================================================
                                RECENT FIXES & IMPROVEMENTS
===============================================================================

INFINITE LOOP FIX
================
Problem: Duplicate subscriptions causing race conditions
Solution: Single subscription with internal parallel processing
Status: ✅ FIXED

CENTRALIZED FILE PROCESSING
===========================
Problem: Duplicate downloads and premature cleanup
Solution: FileManagerService with session tracking
Status: ✅ IMPLEMENTED

PUSH MIGRATION
==============
Problem: Pull-based polling inefficiency
Solution: Push-based webhooks for real-time processing
Status: ✅ MIGRATED

===============================================================================
                                TESTING & VALIDATION
===============================================================================

TEST SCRIPTS
============
- test_pubsub_flow.py - End-to-end flow testing
- test_pubsub_flow_local.py - Local development testing
- test_centralized_file_processing.py - File management testing

VALIDATION POINTS
================
1. Single download per audio file
2. Proper session tracking
3. Coordinated cleanup
4. No infinite loops
5. All analysis services complete
6. Final results aggregation

===============================================================================

This pub/sub flow provides a robust, scalable, and efficient system for 
processing student audio submissions with comprehensive analysis capabilities.
The architecture ensures reliability, performance, and proper resource 
management while maintaining real-time processing capabilities. 